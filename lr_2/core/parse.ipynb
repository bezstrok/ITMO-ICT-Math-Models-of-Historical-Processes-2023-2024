{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:48:22.735715Z",
     "start_time": "2024-04-09T12:48:20.013497Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from itertools import product, islice\n",
    "\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b1841da67e039b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:35.536847Z",
     "start_time": "2024-04-09T12:42:35.531330Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_URL: str = 'https://gorodrabot.ru/salary'\n",
    "KWPARAMS: dict[str, list[str | int, ...]] = json.load(\n",
    "    open('data/kwattrs.json', encoding='utf-8')\n",
    ")\n",
    "PARAMS_LABELS: dict[str, str] = {\n",
    "    'y': 'year',\n",
    "    'mnt': 'month',\n",
    "    'l': 'region',\n",
    "}\n",
    "SALARIES_NAMES: tuple[str, ...] = ('median', 'mean', 'modal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e339d2f2c5a8543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:35.802006Z",
     "start_time": "2024-04-09T12:42:35.796291Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True, kw_only=True)\n",
    "class Salary:\n",
    "    parsed_from: str\n",
    "    year: int\n",
    "    month: str\n",
    "    region: str\n",
    "    median: int | None\n",
    "    mean: int | None\n",
    "    modal: int | None\n",
    "\n",
    "    @classmethod\n",
    "    def from_labels(cls, **kwargs):\n",
    "        kwargs = {PARAMS_LABELS.get(key, key): value for key, value in kwargs.items()}\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1748aa0c96f78e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:36.108336Z",
     "start_time": "2024-04-09T12:42:36.091561Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Proxy:\n",
    "    ip: str\n",
    "    port: str\n",
    "    code: str\n",
    "    country: str\n",
    "    anonymity: str\n",
    "    google: bool\n",
    "    https: bool\n",
    "    last_check: int\n",
    "\n",
    "    @property\n",
    "    def url(self):\n",
    "        return f'http://{self.ip}:{self.port}'\n",
    "\n",
    "\n",
    "class ProxyFactory:\n",
    "    UNITS: dict[str, int] = {\n",
    "        'sec': 1,\n",
    "        'secs': 1,\n",
    "        'min': 60,\n",
    "        'mins': 60,\n",
    "        'hour': 3600,\n",
    "        'hours': 3600\n",
    "    }\n",
    "\n",
    "    URLS: list[str] = [\n",
    "        'https://free-proxy-list.net/',\n",
    "        'https://www.us-proxy.org/',\n",
    "        'https://free-proxy-list.net/uk-proxy.html',\n",
    "        'https://www.sslproxies.org/'\n",
    "    ]\n",
    "\n",
    "    @classmethod\n",
    "    async def create(\n",
    "        cls,\n",
    "        *,\n",
    "        code: list[str] | None = None,\n",
    "        exclude_code: list[str] | None = None,\n",
    "        anonymity: list[str] | None = None,\n",
    "        google: bool | None = None,\n",
    "        https: bool | None = None\n",
    "    ):\n",
    "        \"\"\"Construct proxy factory\"\"\"\n",
    "\n",
    "        self = cls()\n",
    "\n",
    "        self.code = set(code) if code else None\n",
    "        self.exclude_code = set(exclude_code) if exclude_code else None\n",
    "        self.anonymity = set(anonymity) if anonymity else None\n",
    "        self.google = google\n",
    "        self.https = https\n",
    "        self.proxies = iter(await self.get_proxies())\n",
    "\n",
    "        return self\n",
    "\n",
    "    async def get_proxies(self) -> list[Proxy]:\n",
    "        \"\"\"Get proxies from all sources\"\"\"\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = [\n",
    "                asyncio.create_task(self._fetch_proxies(session, url))\n",
    "                for url in self.URLS\n",
    "            ]\n",
    "            results = await asyncio.gather(*tasks)\n",
    "\n",
    "        proxies = self._filter_proxies(\n",
    "            [proxy for result in results for proxy in result]\n",
    "        )\n",
    "        proxies.sort(key=lambda proxy: proxy.last_check)\n",
    "\n",
    "        return proxies\n",
    "\n",
    "    async def get(\n",
    "        self,\n",
    "        *,\n",
    "        timeout: int = 2,\n",
    "        check_url: str = BASE_URL\n",
    "    ) -> Proxy:\n",
    "        \"\"\"Get first working proxy\"\"\"\n",
    "\n",
    "        async with aiohttp.ClientSession(\n",
    "            timeout=aiohttp.ClientTimeout(total=timeout)\n",
    "        ) as session:\n",
    "            for proxy in self.proxies:\n",
    "                try:\n",
    "                    async with session.get(check_url, proxy=proxy.url) as response:\n",
    "                        if response.status == 200:\n",
    "                            return proxy\n",
    "                except aiohttp.ClientError:\n",
    "                    pass\n",
    "                except asyncio.TimeoutError:\n",
    "                    pass\n",
    "            else:\n",
    "                raise ValueError('No working proxy found')\n",
    "\n",
    "    async def _fetch_proxies(\n",
    "        self,\n",
    "        session: aiohttp.ClientSession,\n",
    "        url: str\n",
    "    ) -> list[Proxy]:\n",
    "        async with session.get(url) as response:\n",
    "            doc = await response.text()\n",
    "\n",
    "        soup = BeautifulSoup(doc, 'html.parser')\n",
    "        tags = soup.select('div.fpl-list tbody tr')\n",
    "\n",
    "        proxies = []\n",
    "        for tag in tags:\n",
    "            columns = [td.get_text(strip=True).lower() for td in tag.select('td')[:8]]\n",
    "            ip, port, code, country, anonymity, google, https, last_check = columns\n",
    "\n",
    "            code = code.upper()\n",
    "            google = google == 'yes'\n",
    "            https = https == 'yes'\n",
    "            value, unit = last_check.split()[:2]\n",
    "            last_check = int(value) * self.UNITS[unit]\n",
    "\n",
    "            proxies.append(\n",
    "                Proxy(ip, port, code, country, anonymity, google, https, last_check)\n",
    "            )\n",
    "\n",
    "        return proxies\n",
    "\n",
    "    def _filter_proxies(\n",
    "        self,\n",
    "        proxies: list[Proxy]\n",
    "    ) -> list[Proxy]:\n",
    "        if self.code is not None:\n",
    "            proxies = [proxy for proxy in proxies if proxy.code in self.code]\n",
    "        if self.exclude_code is not None:\n",
    "            proxies = [proxy for proxy in proxies if proxy.code not in self.exclude_code]\n",
    "        if self.anonymity is not None:\n",
    "            proxies = [proxy for proxy in proxies if proxy.anonymity in self.anonymity]\n",
    "        if self.google is not None:\n",
    "            proxies = [proxy for proxy in proxies if proxy.google == self.google]\n",
    "        if self.https is not None:\n",
    "            proxies = [proxy for proxy in proxies if proxy.https == self.https]\n",
    "\n",
    "        return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f77ecec977d18fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:37.347950Z",
     "start_time": "2024-04-09T12:42:36.384063Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "requests_limit: int | None = None\n",
    "params_list: list = list(\n",
    "    dict(zip(KWPARAMS.keys(), values))  #  Add keys\n",
    "    for values in islice(product(*KWPARAMS.values()), requests_limit)  #  Product values\n",
    ")\n",
    "proxy_factory: ProxyFactory = await ProxyFactory.create(https=True)\n",
    "simultaneity_limit: int = 15\n",
    "batch_count: int = 3\n",
    "batch_size: int = len(params_list) // batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6135670eb75297c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:37.368138Z",
     "start_time": "2024-04-09T12:42:37.351936Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "semaphore = asyncio.Semaphore(simultaneity_limit)\n",
    "\n",
    "\n",
    "def extract_salaries(doc: str) -> dict[str, int | None]:\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "    tags = soup.find_all('span', class_='statistics-list-section__item-title', limit=3)\n",
    "    salaries = [int(tag.get_text(strip=True).replace(' ', '')) for tag in tags]\n",
    "    match salaries:\n",
    "        case [median, mean, modal]:\n",
    "            salaries = (median, mean, modal)\n",
    "        case [mean]:\n",
    "            salaries = (None, mean, None)\n",
    "        case []:\n",
    "            salaries = (None, None, None)\n",
    "    return dict(zip(SALARIES_NAMES, salaries))\n",
    "\n",
    "\n",
    "async def parse(session: aiohttp.ClientSession, url: str, **kwargs) -> Salary:\n",
    "    async with semaphore:\n",
    "        async with session.get(url, **kwargs) as response:\n",
    "            doc = await response.text()\n",
    "\n",
    "    salaries = extract_salaries(doc)\n",
    "    params = kwargs.get('params')\n",
    "    return Salary.from_labels(parsed_from=response.url, **params, **salaries)\n",
    "\n",
    "\n",
    "async def parse_all() -> list[Salary]:\n",
    "    docs: list[Salary] = []\n",
    "    async with aiohttp.ClientSession(\n",
    "        connector=aiohttp.TCPConnector(limit=simultaneity_limit),\n",
    "        raise_for_status=True,\n",
    "    ) as session:\n",
    "        for i in tqdm(range(0, len(params_list), batch_size), desc='Parsing'):\n",
    "            proxy = await proxy_factory.get()\n",
    "            tasks = [\n",
    "                parse(\n",
    "                    session,\n",
    "                    BASE_URL,\n",
    "                    params=params,\n",
    "                    proxy=proxy.url,\n",
    "                )\n",
    "                for params in params_list[i : i + batch_size]\n",
    "            ]\n",
    "            results = [\n",
    "                await i\n",
    "                for i in tqdm(\n",
    "                    asyncio.as_completed(tasks),\n",
    "                    total=len(tasks),\n",
    "                    desc=f'Processing {i} - {i + batch_size} urls',\n",
    "                )\n",
    "            ]\n",
    "            docs.extend(results)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9651a9034eab709a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:46:24.296998Z",
     "start_time": "2024-04-09T12:43:18.159117Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b1ad2057054557826f93f1f448b03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Parsing:   0%|          | 0/3 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f80c519486141b48c31ed5a68bd7d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Processing 0 - 896 urls:   0%|          | 0/896 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c1be8b7f374465a60f69aec7fc2536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Processing 896 - 1792 urls:   0%|          | 0/896 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde6cdafaef4be1917437e8f1ae5193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Processing 1792 - 2688 urls:   0%|          | 0/896 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = await parse_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970cb46e622ee20e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:48:26.454973Z",
     "start_time": "2024-04-09T12:48:26.355096Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv('data/salaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f779788ddbd8be3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:48:54.206327Z",
     "start_time": "2024-04-09T12:48:54.195477Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2688 entries, 0 to 2687\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   parsed_from  2688 non-null   object \n",
      " 1   year         2688 non-null   int64  \n",
      " 2   month        2688 non-null   object \n",
      " 3   region       2688 non-null   object \n",
      " 4   median       1931 non-null   float64\n",
      " 5   mean         2687 non-null   float64\n",
      " 6   modal        1931 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 147.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
